# Application
* Ingest csv files w/w.o headers
* Append two colums to the output dataframe
  * ingestion_tms (YYYY-MM-DD HH:mm:SS)
  * use append mode to automatically append new data to delta table

# Dockerize
* spark job
* spark history server

# Deploy
* locally kubernetes + minikube

# docs
[delta lake](https://docs.delta.io/1.2.1/quick-start.html)

# versions
* python: 3.10.12
* pyspark: 3.3.1
* delta: 1.2.1
